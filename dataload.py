'''
æ•°æ®è¯»å–ã€é™é¢‘å¤„ç†å’Œè®¡ç®—æ”¶ç›Šç‡æ¨¡å—
'''

import pandas as pd
import numpy as np
from pathlib import Path
from scipy.optimize import minimize
import time
import talib as ta
from enum import Enum
import re

import pandas as pd
import numpy as np
from pathlib import Path
from scipy.optimize import minimize
import time
import talib as ta
from enum import Enum
import re
import os
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime, timedelta

import sys
import matplotlib.pyplot as plt
from scipy.stats import zscore, kurtosis, skew, yeojohnson, boxcox
from scipy.stats import tukeylambda, mstats
from sklearn.preprocessing import RobustScaler
import zipfile
from io import BytesIO


def data_load(sym: str) -> pd.DataFrame:
    '''æ•°æ®è¯»å–æ¨¡å—'''
    file_name = '/home/etern/crypto/data/merged/merged/' + sym + '-merged-without-rfr-1m.csv'  
    z = pd.read_csv(file_name, index_col=1)[
        ['o', 'h', 'l', 'c', 'vol', 'vol_ccy', 'trades',
               'oi', 'oi_ccy', 'toptrader_count_lsr', 'toptrader_oi_lsr', 'count_lsr',
               'taker_vol_lsr']]
    return z

class DataFrequency(Enum):
    """æ•°æ®é¢‘ç‡æšä¸¾"""
    MONTHLY = 'monthly'  # æœˆåº¦æ•°æ®
    DAILY = 'daily'      # æ—¥åº¦æ•°æ®


def _generate_date_range(start_date: str, end_date: str, read_frequency: DataFrequency = DataFrequency.MONTHLY) -> List[str]:
    """
    ç”Ÿæˆæ—¥æœŸèŒƒå›´åˆ—è¡¨
    
    å‚æ•°:
    start_date: èµ·å§‹æ—¥æœŸ
        - æœˆåº¦æ ¼å¼: 'YYYY-MM' (å¦‚ '2020-01') æˆ– 'YYYY-MM-DD' (è‡ªåŠ¨è½¬æ¢ä¸º 'YYYY-MM')
        - æ—¥åº¦æ ¼å¼: 'YYYY-MM-DD' (å¦‚ '2020-01-01')
    end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼åŒä¸Š
    frequency: æ•°æ®é¢‘ç‡ï¼ˆæœˆåº¦æˆ–æ—¥åº¦ï¼‰
    
    è¿”å›:
    æ—¥æœŸå­—ç¬¦ä¸²åˆ—è¡¨
    """
    if read_frequency == DataFrequency.MONTHLY:
        # å…¼å®¹ 'YYYY-MM' å’Œ 'YYYY-MM-DD' ä¸¤ç§æ ¼å¼
        # å¦‚æœæ˜¯ 'YYYY-MM-DD' æ ¼å¼ï¼Œè‡ªåŠ¨æˆªå–ä¸º 'YYYY-MM'
        new_start_date = start_date
        new_end_date = end_date
        if len(start_date) == 10:  # 'YYYY-MM-DD' æ ¼å¼
            new_start_date = start_date[:7]
        if len(end_date) == 10:
            new_end_date = end_date[:7]
            
        start_dt = datetime.strptime(new_start_date, '%Y-%m')
        end_dt = datetime.strptime(new_end_date, '%Y-%m')
        
        date_list = []
        current_dt = start_dt
        while current_dt <= end_dt:
            date_list.append(current_dt.strftime('%Y-%m'))
            # ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªæœˆ
            if current_dt.month == 12:
                current_dt = current_dt.replace(year=current_dt.year + 1, month=1)
            else:
                current_dt = current_dt.replace(month=current_dt.month + 1)
        
        return date_list
    
    elif read_frequency == DataFrequency.DAILY:
        start_dt = datetime.strptime(start_date, '%Y-%m-%d')
        end_dt = datetime.strptime(end_date, '%Y-%m-%d')
        
        date_list = []
        current_dt = start_dt
        while current_dt <= end_dt:
            date_list.append(current_dt.strftime('%Y-%m-%d'))
            current_dt += timedelta(days=1)
        
        return date_list
    
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®é¢‘ç‡: {frequency}")
    

def data_load_v2(sym: str, data_dir: str, start_date: str, end_date: str, 
                 timeframe: str = '1h', read_frequency: str = 'monthly',
                 file_path: Optional[str] = None) -> pd.DataFrame:
    """
    æ•°æ®è¯»å–æ¨¡å— V2 - æ”¯æŒä»å¤šç§æ—¶é—´ç²’åº¦çš„æ•°æ®æ–‡ä»¶è¯»å–
    
    å‚æ•°:
    sym: äº¤æ˜“å¯¹ç¬¦å·ï¼Œä¾‹å¦‚ 'BTCUSDT'
    data_dir: æ•°æ®ç›®å½•è·¯å¾„ï¼Œä¾‹å¦‚ '/Volumes/Ext-Disk/data/futures/um/monthly/klines/BTCUSDT/1m'
    start_date: èµ·å§‹æ—¥æœŸ
        - æœˆåº¦æ ¼å¼: 'YYYY-MM' (å¦‚ '2020-01')
        - æ—¥åº¦æ ¼å¼: 'YYYY-MM-DD' (å¦‚ '2020-01-01')
    end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼åŒä¸Š
    timeframe: æ—¶é—´å‘¨æœŸï¼Œé»˜è®¤ '1m'ï¼Œå¯é€‰ '5m', '1h' ç­‰
    frequency: æ•°æ®é¢‘ç‡ï¼Œ'monthly'ï¼ˆæœˆåº¦ï¼‰æˆ– 'daily'ï¼ˆæ—¥åº¦ï¼‰
    file_path: ç›´æ¥æŒ‡å®šæ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒ .feather / .zip / .csvï¼‰ï¼ŒæŒ‡å®šåå°†å¿½ç•¥å…¶ä»–å‚æ•°
    
    è¿”å›:
    åŒ…å«æ ‡å‡†åŒ–åˆ—åçš„ DataFrame
    
    æ–‡ä»¶è¯»å–ä¼˜å…ˆçº§:
    1. å¦‚æœæŒ‡å®š file_pathï¼Œç›´æ¥è¯»å–è¯¥æ–‡ä»¶
    2. å¦åˆ™æŒ‰æ—¥æœŸèŒƒå›´è¯»å–ï¼Œä¼˜å…ˆè¯»å– .feather æ ¼å¼æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    3. å¦‚æœ .feather ä¸å­˜åœ¨ï¼Œåˆ™è¯»å– .zip æ–‡ä»¶ï¼Œå¹¶è‡ªåŠ¨ç¼“å­˜ä¸º .feather
    
    ç¤ºä¾‹:
    # è¯»å–æœˆåº¦æ•°æ®
    df = data_load_v2('BTCUSDT', '/path/to/monthly', '2020-01', '2024-09', frequency='monthly')
    
    # è¯»å–æ—¥åº¦æ•°æ®
    df = data_load_v2('BTCUSDT', '/path/to/daily', '2020-01-01', '2020-01-31', frequency='daily')
    
    # ç›´æ¥è¯»å–å•ä¸ªæ–‡ä»¶
    df = data_load_v2('BTCUSDT', '', '', '', file_path='/path/to/data.feather')
    """
    
    # å¦‚æœæŒ‡å®šäº†ç›´æ¥æ–‡ä»¶è·¯å¾„ï¼Œç›´æ¥è¯»å–
    # if file_path:
    #     return _read_direct_file(file_path)
    
    # è§£æé¢‘ç‡å‚æ•°
    try:
        freq_enum = DataFrequency(read_frequency.lower())
    except ValueError:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®é¢‘ç‡: {read_frequency}ï¼Œä»…æ”¯æŒ 'monthly' æˆ– 'daily'")
    
    # ç”Ÿæˆæ—¥æœŸèŒƒå›´
    date_list = _generate_date_range(start_date, end_date, freq_enum)
    
    # è¯»å–æ‰€æœ‰æ—¶é—´æ®µçš„æ•°æ®
    df_list = []
    success_count = 0
    failed_count = 0
    
    for date_str in date_list:
        df = _read_single_period_data(sym, date_str, data_dir, timeframe, freq_enum)
        if df is not None:
            df_list.append(df)
            success_count += 1
        else:
            failed_count += 1
    
    # æ£€æŸ¥æ˜¯å¦æˆåŠŸè¯»å–åˆ°æ•°æ®
    if not df_list:
        raise ValueError(f"æœªèƒ½æˆåŠŸè¯»å–ä»»ä½•æ•°æ®æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„å’Œæ—¥æœŸèŒƒå›´\nè·¯å¾„: {data_dir}\næ—¥æœŸ: {start_date} ~ {end_date}")
    
    print(f"\n{'='*60}")
    print(f"è¯»å–å®Œæˆ: æˆåŠŸ {success_count} ä¸ªï¼Œå¤±è´¥ {failed_count} ä¸ª")
    print(f"{'='*60}\n")
    
    # åˆå¹¶æ‰€æœ‰æ•°æ®
    merged_df = pd.concat(df_list, ignore_index=True)
    print(f"åˆå¹¶åæ€»è¡Œæ•°: {len(merged_df):,}")
    
    # æ ‡å‡†åŒ–åˆ—åå’Œç´¢å¼•
    standardized_df = _standardize_dataframe_columns(merged_df)
    
    print(f"æ•°æ®æ—¶é—´èŒƒå›´: {standardized_df.index.min()} è‡³ {standardized_df.index.max()}")
    print(f"{'='*60}\n")
    
    return standardized_df

def _read_single_period_data(sym: str, date_str: str, data_dir: str, timeframe: str = '1m',
                             frequency: DataFrequency = DataFrequency.MONTHLY) -> Optional[pd.DataFrame]:
    """
    è¯»å–å•ä¸ªæ—¶é—´æ®µçš„æ•°æ®ï¼ˆä¼˜å…ˆ featherï¼Œå…¶æ¬¡ zipï¼‰
    
    å‚æ•°:
    sym: äº¤æ˜“å¯¹ç¬¦å·
    date_str: æ—¥æœŸå­—ç¬¦ä¸²
    data_dir: æ•°æ®ç›®å½•
    timeframe: æ—¶é—´å‘¨æœŸ
    frequency: æ•°æ®é¢‘ç‡
    
    è¿”å›:
    DataFrame æˆ– None
    """
    file_base_name, feather_path, zip_path = _build_file_paths(sym, date_str, data_dir, timeframe, frequency)
    
    # ä¼˜å…ˆè¯»å– feather
    df = _read_feather_file(feather_path)
    if df is not None:
        return df
    
    # å¦‚æœ feather ä¸å­˜åœ¨ï¼Œè¯»å– zip
    df = _read_zip_file(zip_path, file_base_name, save_feather=True)
    if df is not None:
        return df
    
    # ä¸¤ç§æ–‡ä»¶éƒ½ä¸å­˜åœ¨
    print(f"âš  è­¦å‘Šï¼šæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {file_base_name}")
    return None


def _build_file_paths(sym: str, date_str: str, data_dir: str, timeframe: str = '1m', 
                      frequency: DataFrequency = DataFrequency.MONTHLY) -> Tuple[str, str, str]:
    """
    æ„å»ºæ–‡ä»¶è·¯å¾„
    
    å‚æ•°:
    sym: äº¤æ˜“å¯¹ç¬¦å·
    date_str: æ—¥æœŸå­—ç¬¦ä¸²
    data_dir: æ•°æ®ç›®å½•
    timeframe: æ—¶é—´å‘¨æœŸ (å¦‚ '1m', '5m', '1h')
    frequency: æ•°æ®é¢‘ç‡
    
    è¿”å›:
    (file_base_name, feather_path, zip_path) å…ƒç»„
    """
    if frequency == DataFrequency.MONTHLY:
        file_base_name = f"{sym}-{timeframe}-{date_str}"
    elif frequency == DataFrequency.DAILY:
        file_base_name = f"{sym}-{timeframe}-{date_str}"
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®é¢‘ç‡: {frequency}")
    
    # /Volumes/Ext-Disk/data/futures/um/monthly/klines/ETHUSDT/15m/2025/ETHUSDT-15m-2025-01.feather
    year = date_str.split('-')[0]
    feather_path = os.path.join(f'{data_dir}/{year}', f"{file_base_name}.feather")
    zip_path = os.path.join(f'{data_dir}/{year}', f"{file_base_name}.zip")
    
    return file_base_name, feather_path, zip_path

def _read_feather_file(feather_path: str) -> Optional[pd.DataFrame]:
    """
    è¯»å– feather æ ¼å¼æ–‡ä»¶
    
    å‚æ•°:
    feather_path: feather æ–‡ä»¶è·¯å¾„
    
    è¿”å›:
    DataFrame æˆ– Noneï¼ˆå¦‚æœè¯»å–å¤±è´¥ï¼‰
    """
    if not os.path.exists(feather_path):
        return None
    
    try:
        df = pd.read_feather(feather_path)
        print(f"âœ“ æˆåŠŸè¯»å– feather: {os.path.basename(feather_path)}, è¡Œæ•°: {len(df)}")
        return df
    except Exception as e:
        print(f"âœ— è¯»å– feather æ–‡ä»¶å¤±è´¥: {os.path.basename(feather_path)}, é”™è¯¯: {str(e)}")
        return None


def _read_zip_file(zip_path: str, file_base_name: str, save_feather: bool = True) -> Optional[pd.DataFrame]:
    """
    è¯»å– zip æ ¼å¼æ–‡ä»¶ï¼ˆå†…å« CSVï¼‰
    
    å‚æ•°:
    zip_path: zip æ–‡ä»¶è·¯å¾„
    file_base_name: æ–‡ä»¶åŸºç¡€åç§°ï¼ˆä¸å«æ‰©å±•åï¼‰
    save_feather: æ˜¯å¦ä¿å­˜ä¸º feather æ ¼å¼ä»¥åŠ é€Ÿåç»­è¯»å–
    
    è¿”å›:
    DataFrame æˆ– Noneï¼ˆå¦‚æœè¯»å–å¤±è´¥ï¼‰
    """
    if not os.path.exists(zip_path):
        return None
    
    try:
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            # è·å– zip ä¸­çš„ csv æ–‡ä»¶å
            csv_filename = f"{file_base_name}.csv"
            
            if csv_filename not in zip_ref.namelist():
                # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•ä½¿ç”¨ç¬¬ä¸€ä¸ª csv æ–‡ä»¶
                csv_files = [f for f in zip_ref.namelist() if f.endswith('.csv')]
                if csv_files:
                    csv_filename = csv_files[0]
                else:
                    print(f"âœ— åœ¨ {os.path.basename(zip_path)} ä¸­æ‰¾ä¸åˆ° CSV æ–‡ä»¶")
                    return None
            
            # è¯»å– CSV æ•°æ®
            with zip_ref.open(csv_filename) as csv_file:
                df = pd.read_csv(csv_file)
                print(f"âœ“ æˆåŠŸè¯»å– zip: {os.path.basename(zip_path)}, è¡Œæ•°: {len(df)}")
                
                # å¯é€‰ï¼šä¿å­˜ä¸º feather æ ¼å¼ä»¥åŠ é€Ÿåç»­è¯»å–
                if save_feather:
                    feather_path = zip_path.replace('.zip', '.feather')
                    try:
                        df.to_feather(feather_path)
                        print(f"  â†’ å·²ç¼“å­˜ä¸º feather æ ¼å¼")
                    except Exception as e:
                        print(f"  â†’ ä¿å­˜ feather æ–‡ä»¶å¤±è´¥: {str(e)}")
                
                return df
    
    except Exception as e:
        print(f"âœ— è¯»å– zip æ–‡ä»¶å¤±è´¥: {os.path.basename(zip_path)}, é”™è¯¯: {str(e)}")
        return None
    

def _standardize_dataframe_columns(df: pd.DataFrame) -> pd.DataFrame:
    """
    æ ‡å‡†åŒ– DataFrame åˆ—åå¹¶è®¾ç½®ç´¢å¼•
    
    å‚æ•°:
    df: åŸå§‹ DataFrameï¼ˆåŒ…å« Binance æ ¼å¼çš„åˆ—åï¼‰
    
    è¿”å›:
    æ ‡å‡†åŒ–åçš„ DataFrame
    """
    # å°† open_time è½¬æ¢ä¸º datetime å¹¶è®¾ç½®ä¸ºç´¢å¼•
    df = df.copy()
    df['open_time'] = pd.to_datetime(df['open_time'], unit='ms')
    df.set_index('open_time', inplace=True)

    # df['close_time'] = pd.to_datetime(df['close_time'], unit='ms')
    # df.set_index('close_time', inplace=True)
    
    # åˆ—åæ˜ å°„ï¼šæ–°åˆ—å -> æ—§åˆ—å
    # æ–°åˆ—å: open_time,open,high,low,close,volume,close_time,quote_volume,count,taker_buy_volume,taker_buy_quote_volume,ignore
    # æ—§åˆ—å: o, h, l, c, vol, vol_ccy, trades, oi, oi_ccy, toptrader_count_lsr, toptrader_oi_lsr, count_lsr, taker_vol_lsr
    column_mapping = {
        'open': 'o',
        'high': 'h',
        'low': 'l',
        'close': 'c',
        'volume': 'vol',
        'quote_volume': 'vol_ccy',
        'count': 'trades',
        'close_time': 'close_time',
    }
    
    df = df.rename(columns=column_mapping)
    
    # é€‰æ‹©éœ€è¦çš„åˆ—ï¼Œå¯¹äºç¼ºå¤±çš„åˆ—ç”¨ 0 å¡«å……
    required_columns = [
                            'o', 'h', 'l', 'c', 
                            'vol', 
                            'vol_ccy', 
                            'trades',
                        #    'oi', 'oi_ccy', 'toptrader_count_lsr', 'toptrader_oi_lsr', 'count_lsr',
                        #    'taker_vol_lsr', 
                            'close_time', 
                            'taker_buy_volume', 
                            'taker_buy_quote_volume'
                       ]
    
    # ä¸ºç¼ºå¤±çš„åˆ—æ·»åŠ é»˜è®¤å€¼ 0
    for col in required_columns:
        if col not in df.columns:
            df[col] = 0
            print(f"âš  è­¦å‘Šï¼šåˆ— '{col}' ä¸å­˜åœ¨ï¼Œå·²å¡«å……ä¸º 0")
    
    return df[required_columns]

def removed_zero_vol_dataframe(df):
    """
    æ‰“å°å¹¶ä¸”è¿”å›-
    1. volumeè¿™ä¸€åˆ—ä¸º0çš„è¡Œç»„æˆçš„df
    2. lowè¿™ä¸€åˆ—çš„æœ€å°å€¼
    3. volumeè¿™ä¸€åˆ—çš„æœ€å°å€¼
    5. å»é™¤æ‰volume=0çš„è¡Œçš„dataframe
    -------

    """
    # å°†DataFrameçš„ç´¢å¼•åˆ—è®¾ç½®ä¸º'datetime'
    df.index = pd.to_datetime(df.index)

    # 1. volumeè¿™ä¸€åˆ—ä¸º0çš„è¡Œç»„æˆçš„df
    volume_zero_df = df[df['vol'] == 0]
    print(f"Volumeä¸º0çš„è¡Œç»„æˆçš„DataFrame: {len(volume_zero_df)}")

    # 2. lowè¿™ä¸€åˆ—çš„æœ€å°å€¼
    min_low = df['l'].min()
    print(f"Lowè¿™ä¸€åˆ—çš„æœ€å°å€¼: {min_low}")

    # 3. volumeè¿™ä¸€åˆ—çš„æœ€å°å€¼
    min_volume = df['vol'].min()
    print(f"Volumeè¿™ä¸€åˆ—çš„æœ€å°å€¼: {min_volume}")

    # 5. å»é™¤æ‰volume=0çš„è¡Œçš„dataframe
    removed_zero_vol_df = df[df['vol'] != 0]
    print(f"å»é™¤æ‰Volumeä¸º0çš„è¡Œä¹‹å‰çš„DataFrame length: {len(df)}")
    print(f"å»é™¤æ‰Volumeä¸º0çš„è¡Œä¹‹åçš„DataFrame length: {len(removed_zero_vol_df)}")

    return removed_zero_vol_df


def resample(z: pd.DataFrame, freq: str, closed: str = 'left', label: str = 'left') -> pd.DataFrame:
    '''
    è¿™æ˜¯ä¸æ”¯æŒvwapçš„ï¼Œé»˜è®¤è¯»å…¥çš„æ•°æ®æ˜¯æ²¡æœ‰turnoverä¿¡æ¯ï¼Œè‡ªç„¶ä¹Ÿæ²¡æœ‰vwapçš„ä¿¡æ¯ï¼Œä¸éœ€è¦è·å–symçš„ä¹˜æ•°
    '''
    if freq == '15m':
        return z
    
    if freq != '1min' or freq != '1m':
        z.index = pd.to_datetime(z.index)
        # æ³¨æ„closedå’Œlabelå‚æ•°
        z = z.resample(freq, closed=closed, label=label).agg({'o': 'first',
                                                               'h': 'max',
                                                               'l': 'min',
                                                               'c': 'last',
                                                               'vol': 'sum',
                                                               'vol_ccy': 'sum',
                                                               'trades': 'sum',
                                                            #    'oi': 'last', 
                                                            #    'oi_ccy': 'last', 
                                                            #    'toptrader_count_lsr':'last', 
                                                            #    'toptrader_oi_lsr':'last', 
                                                            #    'count_lsr':'last',
                                                            #    'taker_vol_lsr':'last'
                                                               })
        # æ³¨æ„resampleå,æ¯”å¦‚ä»¥10minä¸ºresampleçš„freqï¼Œ9:00çš„æ•°æ®æ˜¯æŒ‡9:00åˆ°9:10çš„æ•°æ®~~
        z = z.fillna(method='ffill')   
        z.columns = ['o', 'h', 'l', 'c', 'vol', 'vol_ccy','trades',
            #    'oi', 'oi_ccy', 'toptrader_count_lsr', 'toptrader_oi_lsr', 'count_lsr',
            #    'taker_vol_lsr'
               ]
        
        # é‡è¦ï¼Œè¿™ä¸ªåˆ æ‰0æˆäº¤çš„æ“ä½œï¼Œä¸èƒ½ç»™5åˆ†é’Ÿä»¥å†…çš„freqè¿›è¡Œæ“ä½œï¼Œå› ä¸ºè¿™ç§æƒ…å†µè¿˜æ˜¯æŒºå®¹æ˜“å‡ºç°æ²¡æœ‰æˆäº¤çš„ï¼Œè¿™ä¼šæ”¹å˜æœ¬èº«çš„åˆ†å¸ƒ
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å¼€å¤´çš„æ•°å€¼éƒ¨åˆ†, åˆ¤æ–­freqçš„å‘¨æœŸ
        match = re.match(r"(\d+)", freq)
        if match:
            int_freq = int(match.group(1))
            if int_freq > 5:
                z = removed_zero_vol_dataframe(z)
        
        return z
    
    return z


def resample_with_offset(z: pd.DataFrame, freq: str, offset: pd.Timedelta = None, 
                        closed: str = 'left', label: str = 'left') -> pd.DataFrame:
    '''
    æ”¯æŒoffsetå‚æ•°çš„resampleå‡½æ•° - ä½¿ç”¨pandasåŸç”Ÿoffsetå‚æ•°ï¼Œé¿å…æ—¶é—´ç´¢å¼•åç§»çš„é—®é¢˜
    
    å‚æ•°:
        z: è¾“å…¥çš„DataFrameï¼Œå¿…é¡»æœ‰DatetimeIndex
        freq: é‡é‡‡æ ·é¢‘ç‡ï¼Œå¦‚ '1h', '2h', '30min'
        offset: åç§»é‡ï¼ˆpd.Timedeltaï¼‰ï¼Œç”¨äºè°ƒæ•´åˆ†æ¡¶èµ·ç‚¹
                ä¾‹å¦‚ï¼šoffset=pd.Timedelta(minutes=15) ä¼šè®©1å°æ—¶æ¡¶ä» 9:15, 10:15, 11:15... å¼€å§‹
        closed: åŒºé—´é—­åˆæ–¹å¼ï¼Œ'left' æˆ– 'right'
        label: æ ‡ç­¾ä½ç½®ï¼Œ'left' æˆ– 'right'
    
    è¿”å›:
        é‡é‡‡æ ·åçš„DataFrame
    '''
    if freq == '15m':
        return z
    
    if freq != '1min' and freq != '1m':
        z.index = pd.to_datetime(z.index)
        
        # ä½¿ç”¨pandasåŸç”Ÿçš„offsetå‚æ•°ï¼Œè€Œä¸æ˜¯åç§»ç´¢å¼•
        if offset is not None:
            z_resampled = z.resample(
                freq, 
                closed=closed, 
                label=label,
                offset=offset  # ğŸ”‘ å…³é”®ï¼šä½¿ç”¨pandasåŸç”Ÿoffsetå‚æ•°
            ).agg({
                'o': 'first',
                'h': 'max',
                'l': 'min',
                'c': 'last',
                'vol': 'sum',
                'vol_ccy': 'sum',
                'trades': 'sum',
            })
        else:
            # æ²¡æœ‰offsetæ—¶ï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
            z_resampled = z.resample(freq, closed=closed, label=label).agg({
                'o': 'first',
                'h': 'max',
                'l': 'min',
                'c': 'last',
                'vol': 'sum',
                'vol_ccy': 'sum',
                'trades': 'sum',
            })
        
        # å‰å‘å¡«å……NaNå€¼
        z_resampled = z_resampled.fillna(method='ffill')
        z_resampled.columns = ['o', 'h', 'l', 'c', 'vol', 'vol_ccy', 'trades']
        
        return z_resampled
    
    return z
    